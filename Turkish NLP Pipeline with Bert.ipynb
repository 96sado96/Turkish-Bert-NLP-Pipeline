{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish NLP Pipeline with BERT \n",
    "\n",
    "1. Sentiment Analysis\n",
    "2. NER Model\n",
    "3. Question Answering\n",
    "4. Text Summarization\n",
    "5. Text Categorization\n",
    "\n",
    "These models are fined tuned based on Turkish-Bert model \n",
    "\n",
    "https://github.com/stefan-it/turkish-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "* python3\n",
    "* pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/savas/.local/lib/python3.7/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.12.32)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /home/savas/.local/lib/python3.7/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/savas/.local/lib/python3.7/site-packages (from transformers) (2017.4.5)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.45.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.41)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.32 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers) (1.15.32)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /home/savas/.local/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/dist-packages (from botocore<1.16.0,>=1.15.32->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /usr/lib/python3/dist-packages (from botocore<1.16.0,>=1.15.32->boto3->transformers) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/lib/python3/dist-packages (from botocore<1.16.0,>=1.15.32->boto3->transformers) (2.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Sentiment Analysis\n",
    "* This model can get up to %95 success rate on our dataset \n",
    "* To see the training detail and the model performce, check the link \\\n",
    " https://huggingface.co/savasy/bert-base-turkish-sentiment-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "# load model, it takes time since it load over 500 MB model file\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "sa= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9967432}]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "p= sa(\"bu telefon modelleri çok kaliteli , her parçası çok özel bence\")\n",
    "print(p)\n",
    "#[{'label': 'LABEL_1', 'score': 0.9871089}]\n",
    "print (p[0]['label']=='LABEL_1')\n",
    "#True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.99860054}]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "p= sa(\"Film çok kötü ve çok sahteydi\")\n",
    "print(p)\n",
    "#[{'label': 'LABEL_0', 'score': 0.9975505}]\n",
    "print (p[0]['label']=='LABEL_1')\n",
    "#False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suppose your file has lots of lines of comment and label (1 or 0) at the end (tab seperated)\n",
    "\n",
    "```\n",
    " # yourfile.tsv\n",
    " comment1 ... \\t label\n",
    " comment2 ... \\t label\n",
    "\n",
    " comment-n ... \\t  label\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# your test code\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "f=\"/path/to/your/file/yourfile.tsv\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "sa= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)\n",
    "\n",
    "i,crr=0,0\n",
    "for line in open(f):\n",
    " lines=line.strip().split(\"\\t\")\n",
    " if len(lines)==2:\n",
    "  i=i+1\n",
    "  if i%100==0:\n",
    "   print(i)\n",
    "  pred= sa(lines[0])\n",
    "  pred=pred[0][\"label\"].split(\"_\")[1]\n",
    "  if pred== lines[1]:\n",
    "   crr=crr+1\n",
    "\n",
    "print(crr, i, crr/i)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Name Entity Recognizer (NER)\n",
    "This model can get %95 accuracy, currently it works with PER, LOC, and ORG\n",
    "\n",
    "check model repo for other detail\n",
    "\n",
    "* https://huggingface.co/savasy/bert-base-turkish-ner-cased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Mustafa', 'score': 0.9938516616821289, 'entity': 'B-PER'},\n",
       " {'word': 'Kemal', 'score': 0.9881671071052551, 'entity': 'I-PER'},\n",
       " {'word': 'Atatürk', 'score': 0.9957979321479797, 'entity': 'I-PER'},\n",
       " {'word': 'Samsun', 'score': 0.9059973359107971, 'entity': 'B-LOC'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
    "\n",
    "ner=pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "ner(\"Mustafa Kemal Atatürk 19 Mayıs 1919'da Samsun'a ayak bastı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'Sait', 'score': 0.9995592832565308, 'entity': 'B-PER'},\n",
       " {'word': 'Faik', 'score': 0.999716579914093, 'entity': 'I-PER'},\n",
       " {'word': 'Bur', 'score': 0.7886330485343933, 'entity': 'B-LOC'},\n",
       " {'word': '##gaz', 'score': 0.8438959121704102, 'entity': 'I-LOC'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"Sait Faik ömrünün sonuna kadar yazları Burgaz adadaki köşklerinde kalmıştır\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Question Answering  (SQuAD) for Turkish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model istranied with TQuAD dataset (which is SQuAD version of Turkish)\n",
    "\n",
    "https://github.com/TQuad/turkish-nlp-qa-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"savasy/bert-base-turkish-squad\")\n",
    "nlp=pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sait=\"ABASIYANIK, Sait Faik. Hikayeci (Adapazarı 23 Kasım 1906-İstanbul 11 Mayıs 1954). \\\n",
    "İlk öğrenimine Adapazarı’nda Rehber-i Terakki Mektebi’nde başladı. İki yıl kadar Adapazarı İdadisi’nde okudu.\\\n",
    "İstanbul Erkek Lisesi’nde devam ettiği orta öğrenimini Bursa Lisesi’nde tamamladı (1928). İstanbul Edebiyat \\\n",
    "Fakültesi’ne iki yıl devam ettikten sonra babasının isteği üzerine iktisat öğrenimi için İsviçre’ye gitti. \\\n",
    "Kısa süre sonra iktisat öğrenimini bırakarak Lozan’dan Grenoble’a geçti. Üç yıl başıboş bir edebiyat öğrenimi \\\n",
    "gördükten sonra babası tarafından geri çağrıldı (1933). Bir müddet Halıcıoğlu Ermeni Yetim Mektebi'nde Türkçe \\\n",
    "gurup dersleri öğretmenliği yaptı. Ticarete atıldıysa da tutunamadı. Bir ay Haber gazetesinde adliye muhabirliği\\\n",
    "yaptı (1942). Babasının ölümü üzerine aileden kalan emlakin geliri ile avare bir hayata başladı. Evlenemedi.\\\n",
    "Yazları Burgaz adasındaki köşklerinde, kışları Şişli’deki apartmanlarında annesi ile beraber geçen bu fazla \\\n",
    "içkili bohem hayatı ömrünün sonuna kadar sürdü.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 135.90it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 1376.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7435662892824979, 'start': 752, 'end': 775, 'answer': 'Babasının ölümü üzerine'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Ne zaman avare bir hayata başladı?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 124.14it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.32522039650666557, 'start': 246, 'end': 262, 'answer': 'Bursa Lisesi’nde'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Sait Faik hangi Lisede orta öğrenimini tamamladı?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 106.97it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 4108.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0804725005957514, 'start': 498, 'end': 515, 'answer': 'edebiyat öğrenimi'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Sait Faik bir film yönetmeni mi?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 139.72it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 3382.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.013415400836009894, 'start': 0, 'end': 11, 'answer': 'ABASIYANIK,'}\n"
     ]
    }
   ],
   "source": [
    "# Ask your self ! type your question\n",
    "print(nlp(question=\"...?\", context=sait))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ataturk=\"Atatürk  modern, ilerici ve laik bir ulus devleti oluşturmak için politik, ekonomik ve kültürel alanlarda sekülarist ve milliyetçi \\\n",
    " karakterdeki reformlarını başlattı. Yabancılara tanınan ekonomik imtiyazlar kaldırıldı ve onlara ait üretim araçları ve demiryolları millîleştirildi. \\\n",
    " Tevhîd-i Tedrîsât Kanunu ile eğitim Türk hükûmetinin denetimine girdi. Seküler ve bilimsel eğitim esas alındı. Binlerce yeni okul inşa edildi. \\\n",
    " İlköğretim ücretsiz ve zorunlu hale getirildi. Yabancı okullar devlet denetimine alındı. Köylülerin sırtına yüklenen ağır vergiler azaltıldı. \\\n",
    " Erkeklerin serpuş ve kıyafetlerinde değişiklikler yapıldı. Takvim, saat ve ölçülerde değişikliklere gidildi. \\\n",
    " Mecelle kaldırılarak yerine seküler Türk Kanunu Medenisi yürürlüğe konuldu. Kadınların sivil ve politik hakları pek çok Batı ülkesinden önce tanındı. \\\n",
    " Çok eşlilik yasaklandı. Kadınların şahitliği ve miras hakkı erkeklerinkiyle eşit hale getirildi. Benzer şekilde, dünyanın çoğu ülkesinden önce olarak \\\n",
    " Türkiye'de kadınların ilkin yerel seçimlerde (1930), sonra genel seçimlerde (1934) seçme ve seçilme hakkı tanındı. Ceza ve borçlar hukukunda \\\n",
    " seküler yasalar yürürlüğe konuldu. Sanayi Teşvik Kanunu kabul edildi. Toprak Reformu için çabalandı.[3] Arap harfleri temelli Osmanlı alfabesinin yerine \\\n",
    "  Latin harfleri temelli yeni Türk alfabesi kabul edildi. Halkı okuryazar kılmak için eğitim seferberliği başlatıldı. Üniversite Reformu gerçekleştirildi. \\\n",
    "  Birinci Beş Yıllık Sanayi Planı yürürlüğe konuldu. Sınıf ve statü farkı gözeten lâkap ve unvanlar kaldırıldı ve soyadları yürürlüğe konuldu. \\\n",
    "  Homojen ve birleşmiş bir ulus yaratılması için Türkleştirme politikası yürütüldü.[4][5][6] Türk olmayan azınlıklar kamuoyunda Türkçe konuşmaya zorlandı,[7] \\\n",
    "  Türkçe olmayan toponomiler ve azınlıkların soyadları Türkçeye çevrildi.[8][9]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 42.30it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 4911.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.17692459754713763, 'start': 168, 'end': 179, 'answer': 'Yabancılara'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"Kimlere ekonomik imtiyaz kaldırıldı?\", context=ataturk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 91.54it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 3942.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 4.634995517165336e-07, 'start': 0, 'end': 8, 'answer': 'Atatürk'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(question=\"tüm bu devrimleri kim yaptı?\", context=ataturk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 84.40it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6009.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.0014260291964551947, 'start': 1797, 'end': 1811, 'answer': 'çevrildi.[8][9]'}\n"
     ]
    }
   ],
   "source": [
    "# Ask your self ! type your question\n",
    "print(nlp(question=\"...?\", context=ataturk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...will be soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Text Categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " .. will be soon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
